# 2.6 Goodness of fit & $\chi^2$ Test

Deviance cannot be used as a measure of fit for binary response GLM. Hence what do we use to measure the fit of a Binary GLM?

Hosmer-Lemeshow statistic!
ROC curve is used to present the goodness of fit.

## Hosmer-Lemeshow statistic
```{math}
:label: HLS
H &= \sum_{i=1}^{G} \frac{(O_{i} - E_{i})^2}{E_{i}(1 - E_{i}/n_{i})}

 &= \sum_{j=1}^{J} \frac{(y_j -m_j\bar{\hat{p_j}})^2}{ m_j \bar{\hat{p_j} (1 - \bar{\hat{p_j}})}}
```

where:

  $H$ is the Hosmer-Lemeshow statistic. 

  $G$ is the number of groups or bins.

  $O_{i}$  is the observed number of outcomes in the ith group.

  $E_{i}$ is the expected number of outcomes in the ith group.

  $n_{i}$ is the total number of observations in the ith group.


## Hypothesis test with p-value

> 1-pchisq(94.28042, 100-1) #  0.6153527

```{admonition} Is there a lack of fit in this model?
:class: dropdown
No. p-value > 0.05, no evidence to reject the H0: the model provides the good fit. # Reasoning: as we are comparing the current model with the full model. H0 always thinks that the smaller model gives a better fit. (and the current model is the smaller model)
```

## ROC Curve
> The plot of sensitivity vs. 1 – specificity (also called false positive rate) is named the ROC curve.
### Confusion Matrix

|          | Predicted Negative | Predicted Positive |
|----------|-------------------|-------------------|
| **Actual Negative** | True Negative (TN) | False Positive (FP) |
| **Actual Positive** | False Negative (FN) | True Positive (TP) |

Specificity rate: TN / (TN + FP)

Sensitivity rate: TP / (TP + FN)

```{admonition} Recall
:class: dropdown
specificity rate: predicted correct no / actual no

sensitivity rate: predicted correct yes / actual yes 

where actual no = predicted correct no + predicted incorrect no (i.e. actual no but pred yes)

```


## Pearson’s Chi-square test for goodness of fit

If yi is the observed binomial response for group i with group size mi
```{math}
:label: chi
X^2 = \sum_{i} \frac{(y_i - m_i \hat {\pi_i})^2}{m_i \hat {\pi_i}(1-\hat{\pi_i})} = \sum_{i} \frac{(y_i -\hat{y_i})^2}{\hat{Var}(y_i)}

```
where the sum is taken over all **"successe"**.

If yi is a count (frequency) number in cell i of a contingency table
```{math}
:label: chi2
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} = \sum_{i} \frac{(y_i -\hat{y_i})^2}{\hat{y_i}} =  \sum_{i} \frac{(y_i -\hat{y_i})^2}{\hat{Var}(y_i)}
```
where the sum is taken over all **"successe" and “failures”**.

```{code} To get $\chi^2$ from R
sum(resid(vote.1,type="pearson")^2)
```