# 4.1 Intro
**Logistic Regression** 
> Logistic Regression is a **special form** of log-linear model.
**Log-linear Models**

# 4.2 Examples
## Example1: Car preferences
Male
|      Male      |           |Preference      |
|------------|-----------|----------------|
| Residience | Local     |  Imported      |
| City       |    168    |       68       |
| Country    |    32     |       12       |

Female
|      Female      |           |Preference      |
|------------|-----------|----------------|
| Residience | Local     |  Imported      |
| City       |    84    |       16       |
| Country    |    164     |       24       |


Total

|      Combined      |           |Preference      |
|------------|-----------|----------------|
| Residience | Local     |  Imported      |
| City       |    252    |       84       |
| Country    |    196     |       36       |


## Example 2.Voting behaviour
```{image} /image/voting.png
:alt: voting
:class: bg-primary mb-1
:width: 300px
:align: center
```
> The aim is to find how the probability of voting for Reagan is related to Political Views.

```
voting<-read.csv("C:/Users/qguoqi/OneDrive - The University of Melbourne/
                My Documents/MAST90139/data/voting.csv")
plot(voting$views, voting$reagan/voting$total,
                 xlab="Political Views", ylab="Proportion for Reagan")
```
```{math}
```
We assume that $Y_i \stackrel{d}{=} Bin(n_i, \pi_i)$ and follows a logistic regression model 
$ logit(\pi) = \beta_0 + \beta_1x_i$
where xi = i is the political view of group i

By fitting the model, we get $ \hat{\beta_0} = -2.045; \hat{\beta_1} = 0.496$

### Empirical logits 
$$
emp.logit(\pi)= ln(\frac{y + 0.5}{n - y +0.5})
$$

### Code
```{code}
vote.1 <- glm(reagan/total ~ views, family=binomial, weight=total, data=vote.dat)

summary(vote.1)


```