# 3.2 Model Adeuqacy & Model Comparison
Similar contents discussed in [](c2.2.md) - Test Model Adequacy (Code)
```{math}
```

## Tests of adequacy of fit
>  The adequacy of a model M can be assessed by comparing the likelihood of the model M with the likelihood of the ‘full (saturated) model’.

Test statistic is defined as **residual deviance**
$$
D = 2 \phi [lnL (\hat{\beta_F}) - ln(\hat{\beta_M}) ]
$$

```{admonition} What does big D indicate?
:class: dropdown
model is of poor fit.
```

Testing is based on the result
$$\phi ^{-1} D\stackrel{d}{\approx}X^2 (n-q)$$ if model M is correct

model M is acceptable if $D < \chi^2_{0.95} (n-q)$

```{admonition} Why accept when it's smaller ?
:class: dropdown
Because smaller D is preferred.
```
### Theory behind the model adequacy test
$$
lnL(\beta) \approx lnL(\hat{\beta}) + (\beta - \hat{\beta})^T u(\hat{\beta}) - 1/2 (\beta - \hat{\beta})^{T}J(\hat{\beta})(\beta - \hat{\beta})
$$
from which it follows that (Note $u(\hat{\beta}) = 0$ at MLE($\beta$))
$$
2[lnL(\hat{\beta}) - lnL(\beta)] \approx (\beta - \hat{\beta})^{T}J(\hat{\beta})(\beta - \hat{\beta}) \stackrel{d}{\approx}X^2(q)
$$

### Deviance Residual
Since D = $\sum_{i=1}^{n} d_i^2$ with $ d_i^2$ being the contribution from the i-th observation, deviance residual for obervation i is defined to be:

$$
r_i = sign(y_i - \hat(y_i))|d_i|, i = 1,..., n
$$

```{admonition} what's the difference between deviance residual and residual deviance?
:class: dropdown

**Deviance Residual**: Deviance residuals are a type of residual that measure the discrepancy between observed and predicted outcomes in the context of generalized linear models (GLMs). They are defined based on the deviance function, which quantifies the difference between the observed data and the fitted model.

Deviance residuals are calculated as the signed square root of the deviance contribution for each individual data point. They provide a measure of how well the model predicts each observation relative to the overall model fit. Deviance residuals can be positive or negative, indicating whether the observed outcome is overdispersed or underdispersed compared to the model predictions.

**Residual Deviance**: The residual deviance, on the other hand, is a global measure of model fit for a GLM. It is calculated as the difference between the saturated model deviance and the deviance of the fitted model.

The saturated model is a hypothetical model that perfectly fits the observed data, meaning it has the maximum possible deviance. The residual deviance reflects the remaining deviance that the fitted model cannot explain. Lower residual deviance indicates better model fit, and it is often used for comparing different models or assessing the improvement of a model compared to a null model.

```

### $\Delta$D

```{code}
> anova(pr.1, test = "Chi")

Df Deviance Resid. Df Resid. Dev P(>|Chi|) 
NULL                8   18.4206 
x     1 15.4819     7   2.9387      0.0001

```
```{admonition} $\Delta$D? How do we compare with $\chi^2$
:class: dropdown
$\Delta$=D0 - $\Delta$D1 =15.48

$\chi^2_{0.95}(1) = 3.841$
```

## Comparison of models
by $\Delta$D

## Example
```{code}
Analysis of Deviance Table

Model 1: Y/N ~ CHOL
Model 2: Y/N ~ CHOL + BP
  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    
1        12    26.8050                          
2         9     8.0762  3   18.729 0.0003111 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

qchisq(0.95, df = 12) # 21.02607
qchisq(0.95, df = 9)  # 16.91898
qchisq(0.95, df = 3) # 7.814728
```

### Tests of adequacy of fit
```{admonition} Adequacy of M1 & M2?
:class: dropdown
Model 1: 26.8050 > 21.02607. Hence M(1) is not adequate at 5% level.

Model 2: 8.0762  < 16.91898. Hence M(2) is adequate at 5% level.
```

### Comparison of models [M(1) versus M(2)]
```{admonition} M1 or M2 better?
:class: dropdown
26.8050 -16.91898 = 9.88602 > 7.814728

hence model M(2) is significantly better than model M(1), i.e. $\beta_{BP} \neq 0$ at the 0.1% level.
```